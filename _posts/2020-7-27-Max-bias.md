---
title:  "Maximization Bias (Double Q-Learning)"
date:   2020-07-27 16:10:15 +1000
categories: jekyll update
permalink: /RL_notes/max-bias/
---
<div style="text-align:center"><img src="/files/Chapter6/Max_Bias/MB_p2.PNG" alt="drawing" width="500"/></div>
*(source: Reinforcement Learning: An Introduction, 2nd Edition, by Richard S. Sutton and Andrew G. Barto)*

This is Example 6.7 in RL book.

## **Problem discription**

Look at the figure above, it is a standard TD control problem. The agent always starts at point A, and it needs to decide which action to take in order to get the maximum reward

**State:** A or B \
**Action:** left or right at A, [n] at B \
**Reward:** Notice that the reward of actions from state B is not predefined, but is randomly generated every time an action is taken. The reward for all actions at state A is zero.

## **Implementation**

### Example 6.7

The algorithm (Q-learning) and (Double Q-learning) for this problem is given in the book.
<div style="text-align:center"><img src="/files/Chapter6/Max_Bias/CW_p2.PNG" alt="drawing" width="600"/></div>
*(source: Reinforcement Learning: An Introduction, 2nd Edition, by Richard S. Sutton and Andrew G. Barto)*
<div style="text-align:center"><img src="/files/Chapter6/Max_Bias/MB_p1.PNG" alt="drawing" width="600"/></div>
*(source: Reinforcement Learning: An Introduction, 2nd Edition, by Richard S. Sutton and Andrew G. Barto)*


It is straight forward to plot Figure 6.5 in the book as follows. The book does not tell the value of alpha, here we choose $$\alpha=0.1$$.

<div style="text-align:center"><img src="/files/Chapter6/Max_Bias/history.png" alt="drawing" width="600"/></div>



## **Code Usage**

Download the code [Max_bias](https://github.com/MingruiSun2019/RLbook_reproducing/tree/master/Chapter6/Max_bias).

To generate Figure 6.5 in the book:

{% highlight Bash %}
python3 Q_bias.py -o 1
python3 Q_bias.py -o 2
python3 plot_history.py {% endhighlight %}






**The End**
